{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CodePic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BaseLine 코드(CO2,TEMP)"
      ],
      "metadata": {
        "id": "2Jal8wbbw9cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델이 훈련 할 떄 time window 반환\n",
        "# history_size : 과거 information window의 크기(몇개의 데이터를 학습할것인지)\n",
        "# target_size : 예측해야하는 레이블(얼마나 멀리있는 예측을 배워야 하는것인가)\n",
        "def univariate_data(dataset, start_index, end_index, history_size, target_size):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i) # Reshape data from (history_size,) to (history_size, 1)\n",
        "    data.append(np.reshape(dataset[indices], (history_size, 1)))\n",
        "    labels.append(dataset[i+target_size])\n",
        "  return np.array(data), np.array(labels)\n",
        "\n",
        "# uni data : 단일 특성만 사용하여 모델 학습\n",
        "uni_train_mean = uni_data[:TRAIN_SPLIT].mean()\n",
        "uni_train_std = uni_data[:TRAIN_SPLIT].std()\n",
        "# 데이터 표준화\n",
        "uni_data = (uni_data-uni_train_mean)/uni_train_std\n",
        "\n",
        "# 모델의 마지막 20개의 온도 관측치를 제공\n",
        "univariate_past_history = 20\n",
        "univariate_future_target = 0\n",
        "\n",
        "x_train_uni, y_train_uni = univariate_data(uni_data, 0, TRAIN_SPLIT, univariate_past_history, univariate_future_target)\n",
        "x_val_uni, y_val_uni = univariate_data(uni_data, TRAIN_SPLIT, None, univariate_past_history, univariate_future_target)\n",
        "\n",
        "# time_step\n",
        "def create_time_steps(length):\n",
        "  return list(range(-length, 0))\n",
        "\n",
        "# Show Plot\n",
        "def show_plot(plot_data, delta, title):\n",
        "  labels = ['History', 'True Future', 'Model Prediction']\n",
        "  marker = ['.-', 'rx', 'go']\n",
        "  time_steps = create_time_steps(plot_data[0].shape[0])\n",
        "  if delta:\n",
        "    future = delta\n",
        "  else:\n",
        "    future = 0\n",
        "\n",
        "  plt.title(title)\n",
        "  for i, x in enumerate(plot_data):\n",
        "    if i:\n",
        "      plt.plot(future, plot_data[i], marker[i], markersize=10, label=labels[i])\n",
        "    else:\n",
        "      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label=labels[i])\n",
        "  plt.legend()\n",
        "  plt.xlim([time_steps[0], (future+5)*2])\n",
        "  plt.xlabel('Time-Step')\n",
        "  return plt\n",
        "\n",
        "# Show True Future \n",
        "show_plot([x_train_uni[0], y_train_uni[0]], 0, 'Sample Example')\n",
        "\n",
        "# base line(모델 학습 전 기준 설정)\n",
        "def baseline(history):\n",
        "  return np.mean(history)\n",
        "\n",
        "# Show Plot with Model Prediction\n",
        "show_plot([x_train_uni[0], y_train_uni[0], baseline(x_train_uni[0])], 0, 'Baseline Prediction Example')"
      ],
      "metadata": {
        "id": "elfn62H3KVMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample LSTM(CO2,TEMP)"
      ],
      "metadata": {
        "id": "cx4plNb1yXNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 100\n",
        "\n",
        "train_univariate = tf.data.Dataset.from_tensor_slices((x_train_uni, y_train_uni))\n",
        "train_univariate = train_univariate.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "\n",
        "val_univariate = tf.data.Dataset.from_tensor_slices((x_val_uni, y_val_uni))\n",
        "val_univariate = val_univariate.batch(BATCH_SIZE).repeat()\n",
        "# SimpleLSTM Model(샘플 예측 프로그램)\n",
        "simple_lstm_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.LSTM(8, input_shape=x_train_uni.shape[-2:]),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "# fitting\n",
        "simple_lstm_model.fit(train_univariate, epochs=EPOCHS,\n",
        "                      steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                      validation_data=val_univariate, validation_steps=50)"
      ],
      "metadata": {
        "id": "0oObiZCwZGQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SingleStepModel"
      ],
      "metadata": {
        "id": "ffFaTORayu6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_considerd = ['temp', 'co2']\n",
        "features = df1[features_considerd]\n",
        "features.index = df1['date']\n",
        "features.head()\n",
        "# Rescale\n",
        "dataset = features.values\n",
        "data_mean = dataset[:TRAIN_SPLIT].mean(axis=0)\n",
        "data_std = dataset[:TRAIN_SPLIT].std(axis=0)\n",
        "# 표준화\n",
        "dataset = (dataset-data_mean)/data_std\n",
        "# 여러개의 특성\n",
        "# 제공된 일부 데이터 기반으로 미래의 단일 지점 예측 방법 학습\n",
        "# step_size를 기반으로 관측치를 샘플링\n",
        "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
        "                      target_size, step, single_step=False):\n",
        "  data = []\n",
        "  labels = []\n",
        "\n",
        "  start_index = start_index + history_size\n",
        "  if end_index is None:\n",
        "    end_index = len(dataset) - target_size\n",
        "\n",
        "  for i in range(start_index, end_index):\n",
        "    indices = range(i-history_size, i, step)\n",
        "    data.append(dataset[indices])\n",
        "\n",
        "    if single_step:\n",
        "      labels.append(target[i+target_size])\n",
        "    else:\n",
        "      labels.append(target[i:i+target_size])\n",
        "\n",
        "  return np.array(data), np.array(labels)\n",
        "\n",
        "past_history = 20\n",
        "future_target = 10\n",
        "STEP = 1\n",
        "\n",
        "x_train_single, y_train_single = multivariate_data(dataset, dataset[:, 1], 0,\n",
        "                                                   TRAIN_SPLIT, past_history,\n",
        "                                                   future_target, STEP,\n",
        "                                                   single_step=True)\n",
        "x_val_single, y_val_single = multivariate_data(dataset, dataset[:, 1],\n",
        "                                               TRAIN_SPLIT, None, past_history,\n",
        "                                               future_target, STEP,\n",
        "                                               single_step=True)\n",
        "\n",
        "# SingelStep Model\n",
        "single_step_model = tf.keras.models.Sequential()\n",
        "single_step_model.add(tf.keras.layers.LSTM(32,input_shape=x_train_single.shape[-2:]))\n",
        "single_step_model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "single_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='mae')\n",
        "\n",
        "# fitting\n",
        "single_step_history = single_step_model.fit(train_data_single, epochs=EPOCHS,\n",
        "                                            steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                            validation_data=val_data_single,\n",
        "                                            validation_steps=50)"
      ],
      "metadata": {
        "id": "UVNosyP7YyJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MultiStep"
      ],
      "metadata": {
        "id": "91lVDesay_If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 데이터 플로팅\n",
        "# 미래 시퀀스 예측\n",
        "def multi_step_plot(history, true_future, prediction):\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  num_in = create_time_steps(len(history))\n",
        "  num_out = len(true_future)\n",
        "\n",
        "  plt.plot(num_in, np.array(history[:, 1]), label='History')\n",
        "  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n",
        "           label='True Future')\n",
        "  if prediction.any():\n",
        "    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
        "             label='Predicted Future')\n",
        "  plt.legend(loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "# MultiStep Model\n",
        "multi_step_model = tf.keras.models.Sequential()\n",
        "multi_step_model.add(tf.keras.layers.LSTM(32,\n",
        "                                          return_sequences=True,\n",
        "                                          input_shape=x_train_multi.shape[-2:]))\n",
        "\n",
        "multi_step_model.add(tf.keras.layers.LSTM(16, activation='relu'))\n",
        "multi_step_model.add(tf.keras.layers.Dense(10))\n",
        "\n",
        "# compile\n",
        "multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae')\n",
        "\n",
        "# fitting\n",
        "multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n",
        "                                          steps_per_epoch=EVALUATION_INTERVAL,\n",
        "                                          validation_data=val_data_multi,\n",
        "                                          validation_steps=50)"
      ],
      "metadata": {
        "id": "O4_tf6XXy-od"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}